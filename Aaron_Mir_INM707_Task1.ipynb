{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# INM707 Coursework\n",
    "### Aaron Mir (Student Number: 160001207)\n",
    "<img src=\"All_Tasks.png\" alt=\"All_TasksOverview\" width=\"700\"/>  <img src=\"Task_1.png\" alt=\"Task_1\" width=\"700\"/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Environment: The agent is preparing for an upcoming mission in which they are to infiltrate an enemy stronghold to gather intelligence on a potential coup d'Ã©tat. The enemy land is in the form of an NxN grid with each grid containing one stronghold of size N/2 x N or N x N/2 (starting on either side of the middle column (randomly decided)) and a wide river surrounding the entire enemy land. The stronghold has as many entrances from the mainland as 1/4*N and contains dangerous enemy combatants (at random positions) within the stronghold that move around per step (stochasticity). The land inside the stronghold has no transition probability associated with it (deterministic). The land surrounding the stronghold (the shore) is booby-trapped and covered in mist which means that there is both land which can kill the agent as well as normal land and a transition probability associated with each step (stochasticity) outside the stronghold. The amount of shore that has traps on it is 1/4 of the shore. The goal of the agent is to infiltrate the stronghold and gather the intelligence without being seen/killed by enemy combatants or booby traps.\n",
    "\n",
    "The agent starts in a random cell which belongs to the land surrounding the stronghold.\n",
    "\n",
    "Rewards: +10 for getting intelligence, -100 for getting killed by a combatant or booby trap, -1 for moving into a wall or water\n",
    "\n",
    "Terminal States: agent moves to the intelligence, if agent moves to a trap and dies, if the agent moves to an enemy combatant.\n",
    "\n",
    "N represents normal land [0], X represents a river [1], A represents the agent [2], W represents a wall [3], T represents a booby trap [4], E represents an enemy [5], I represents the intelligence [6]\n",
    "\n",
    "More entrances the bigger the grid?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "You don't need reward matrix and transition probability for q-learning\n",
    "\n",
    "Task 1 should be visualisation and defining the stuff\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "size = 20\n",
    "land = np.zeros((size, size))\n",
    "land[0,:] = 1  \n",
    "land[:,0] = 1\n",
    "land[:,size-1] = 1\n",
    "land[size-1,:] = 1  \n",
    "print(land)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 3. 3. 3. 0. 0. 3. 3. 0. 3. 3. 3. 3. 3. 3. 3. 3. 0. 0. 1.]\n [1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 1.]\n [1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 1.]\n [1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 1.]\n [1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 1.]\n [1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 1.]\n [1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 1.]\n [1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 1.]\n [1. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# try to make more efficient\n",
    "choice = np.random.choice(('row', 'column')) # randomly deciding whether the stronghold will start 1 cell away from the middle row or middle column.\n",
    "if choice == 'row':\n",
    "    row_choice = np.random.choice((size//2, size//2+1, size//2-1))\n",
    "    land[row_choice, 1:size-1] = 3\n",
    "    if row_choice == size//2:\n",
    "        choice_side = np.random.choice(('up', 'down'))\n",
    "        print(choice_side)\n",
    "        if choice_side == 'up':\n",
    "            row_choice == size//2-1\n",
    "        if choice_side == 'down':\n",
    "            row_choice == size//2+1\n",
    "    if row_choice == size//2-1:\n",
    "        land[0:row_choice, 1] = 3\n",
    "        land[0:row_choice, size-2] = 3\n",
    "        land[0, 1:size-1] = 3\n",
    "        traps = []\n",
    "        for i in range(int(np.round(1/4*len(land[row_choice:size-2:,1:size-2]))))     # make as many traps as 1/4 of the shore NOT RIGHT\n",
    "            trap = np.random.choice(np.setdiff1d(range(len(land[row_choice:size-2:,1:size-1])), traps))\n",
    "            land[row_choice:size-2:,1:size-1][trap] = 4\n",
    "            traps.append(trap)\n",
    "    if row_choice == size//2+1:\n",
    "        land[row_choice:size, 1] = 3\n",
    "        land[row_choice:size, size-2] = 3\n",
    "        land[size-1, 1:size-1] = 3\n",
    "        traps = []\n",
    "        for i in range(int(np.round(1/4*len(land[1:row_choice,1:size-1]))))     \n",
    "            trap = np.random.choice(np.setdiff1d(range(len(land[1:row_choice,1:size-1])), traps))\n",
    "            land[1:row_choice,1:size-1][trap] = 4\n",
    "            traps.append(trap)\n",
    "    entrances = []\n",
    "    for i in range(int(np.round(1/4*len(land[row_choice,2:size-2])))+1):        # make as many entrances as 1/4 of the length of the front wall\n",
    "        entrance = np.random.choice(np.setdiff1d(range(len(land[row_choice,2:size-1])), entrances))\n",
    "        land[row_choice,2:size-1][entrance] = 0\n",
    "        entrances.append(entrance_choice)\n",
    "    \n",
    "if choice == 'column':                  # above repeated for the column choice\n",
    "    column_choice = np.random.choice((size//2, size//2+1, size//2-1))\n",
    "    land[1:size-1, column_choice] = 3\n",
    "    if column_choice == size//2:\n",
    "        choice_side = np.random.choice(('left', 'right'))\n",
    "        print(choice_side)\n",
    "        if choice_side == 'left':\n",
    "            column_choice == size//2-1\n",
    "        if choice_side == 'right':\n",
    "            column_choice == size//2+1\n",
    "    if column_choice == size//2-1:\n",
    "        land[1, 0:column_choice] = 3\n",
    "        land[size-2, 0:column_choice] = 3\n",
    "        land[1:size-1, 0] = 3\n",
    "        traps = []\n",
    "        for i in range(int(np.round(1/4*len(land[1:size-2, 1:column_choice]))))     \n",
    "            trap = np.random.choice(np.setdiff1d(range(len(land[1:size-2, 1:column_choice])), traps))\n",
    "            land[1:size-2, 1:column_choice][trap] = 4\n",
    "            traps.append(trap)\n",
    "    if column_choice == size//2+1:\n",
    "        land[1, column_choice:size] = 3\n",
    "        land[size-2, column_choice:size] = 3\n",
    "        land[1:size-1, size-1] = 3\n",
    "        traps = []\n",
    "        for i in range(int(np.round(1/4*len(land[1:size-2, column_choice:size-2]))))     \n",
    "            trap = np.random.choice(np.setdiff1d(range(len(land[1:size-2, column_choice:size-2])), traps))\n",
    "            land[1:size-2, column_choice:size-2][trap] = 4\n",
    "            traps.append(trap)\n",
    "    entrances = []\n",
    "    for i in range(int(np.round(1/4*len(land[2:size-1, column_choice])))+1):\n",
    "        entrance = np.random.choice(np.setdiff1d(range(len(land[2:size-1, column_choice])), entrances))\n",
    "        land[2:size-1, column_choice][entrance] = 0\n",
    "        entrances.append(entrance_choice)\n",
    "print(land)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [1. 3. 3. 3. 0. 0. 3. 3. 0. 3. 3. 3. 3. 3. 3. 3. 3. 0. 0. 1.]\n [1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 1.]\n [1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 1.]\n [1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 1.]\n [1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 1.]\n [1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 1.]\n [1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 1.]\n [1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 1.]\n [1. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(land)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "np.size(land[1:row_choice,1:size-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traps = []\n",
    "for i in range(int(np.round(1/4*np.size(land[1:row_choice,1:size-1]))))     \n",
    "    trap = np.random.choice(np.setdiff1d(range(len(land[1:row_choice,1:size-1])), traps))\n",
    "    land[1:row_choice,1:size-1][trap] = 4\n",
    "    traps.append(trap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([3., 0., 3.])"
      ]
     },
     "metadata": {},
     "execution_count": 200
    }
   ],
   "source": [
    "np.random.choice(land[2:size-1, 7], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stronghold():\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.actions = {0: 'Up', 1: 'Down', 2: 'Left', 3: 'Right'}\n",
    "        self.land = self.env_gen()\n",
    "\n",
    "    def env_gen(self):\n",
    "        land = np.zeros((self.size, self.size))\n",
    "        land[0,:] = 1\n",
    "        land[:,0] = 1\n",
    "        land[self.size-1,:] = 1\n",
    "        land[:,self.size-1] = 1\n",
    "        return land\n",
    "    \n",
    "    def step(self, action):\n",
    "        \n",
    "        return next_state, reward, done\n",
    "    \n",
    "    def reset():\n",
    "        pass\n",
    "\n",
    "    def render(): # displays\n",
    "        pass\n",
    "''' Don't need this for Q-learning\n",
    "    def fill_transition_probability(self): # p.106\n",
    "        \n",
    "        return P\n",
    "    \n",
    "    def fill_reward_matrix(self):\n",
    "        \n",
    "        return R\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policies():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def random_policy(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Stronghold(10)"
   ]
  }
 ]
}