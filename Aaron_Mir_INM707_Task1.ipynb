{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# INM707 Coursework\n",
    "### Aaron Mir (Student Number: 160001207)\n",
    "<img src=\"All_Tasks.png\" alt=\"All_TasksOverview\" width=\"700\"/>  <img src=\"Task_1.png\" alt=\"Task_1\" width=\"700\"/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##--------------------Coding References---------------------##\n",
    "# Percentage of borrowed code: X% - \n",
    "# [1] "
   ]
  },
  {
   "source": [
    "Environment: The agent is preparing for an upcoming mission in which they are to infiltrate an enemy stronghold to gather intelligence on a potential coup d'Ã©tat. The enemy land is in the form of an NxN grid with each grid containing one stronghold of size N/2 x N or N x N/2 (starting on either side of the middle column (randomly decided)) and a wide river surrounding the entire enemy land. The stronghold has as many entrances from the mainland as (1/4)N and contains dangerous enemy combatants (at random positions) within the stronghold that move around per step (stochasticity). The land inside the stronghold has no transition probability associated with it (deterministic). The land surrounding the stronghold (the shore) is booby-trapped and covered in mist which means that there is both land which can kill/hurt the agent as well as normal land and a transition probability associated with each step (stochasticity) outside the stronghold. The amount of shore that has traps on it is (1/4)N x rows of shore. The row/column of values immediately beside the stronghold is normal land. The goal of the agent is to infiltrate the stronghold and gather the intelligence without being seen/killed by enemy combatants or booby traps.\n",
    "\n",
    "The agent starts in a random cell which belongs to the land surrounding the stronghold.\n",
    "\n",
    "Rewards: +10 for getting intelligence, -100 for getting hurt by a combatant or booby trap, -1 for moving into a wall or water\n",
    "\n",
    "Terminal States: agent moves to the intelligence, if agent moves to a trap and dies, if the agent moves to an enemy combatant, if agent runs out of time\n",
    "\n",
    "_ represents normal land [0], X represents a river [1], A represents the agent [2], W represents a wall [3], T represents a booby trap [4], E represents an enemy [5], I represents the intelligence [6]\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "You don't need reward matrix and transition probability for q-learning\n",
    "\n",
    "Task 1 should be visualisation and defining the stuff\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Checklist:\n",
    "    \n",
    "    1. Estabilish states (done, represented by the coordinates of the agent on the grid)\n",
    "    2. Estabilish transitions and transition probability.\n",
    "    3. Estabilish rewards.\n",
    "    "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stronghold():\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.actions = {0: 'Up', 1: 'Down', 2: 'Left', 3: 'Right'}\n",
    "        self.land = self.env_gen()\n",
    "        self.position_agent = None                                 # initial position of the agent will be decided by resetting the environment\n",
    "        self.time_elapsed = 0                                      # run time\n",
    "        self.time_limit = self.size**2\n",
    "        self.dict_map_display={ 0:'_',\n",
    "                                1:'X',\n",
    "                                2:'A',\n",
    "                                3:'W',\n",
    "                                4:'T',\n",
    "                                5:'E',\n",
    "                                6:'I'}\n",
    "    def env_gen(self):\n",
    "        land = np.zeros((self.size, self.size))\n",
    "        land[0,:] = 1                                               # establish the river wall\n",
    "        land[:,0] = 1\n",
    "        land[self.size-1,:] = 1\n",
    "        land[:,self.size-1] = 1\n",
    "        self.column_choice = np.random.choice((self.size//2-1, self.size//2+1)) # random choice whether stronghold starts from the left or right of the 'central' column\n",
    "        land[1:self.size-1, self.column_choice] = 3\n",
    "        if self.column_choice == self.size//2-1:                              # if stronghold is on left\n",
    "            land[1, 0:self.column_choice] = 3                                # establish the walls of stronghold\n",
    "            land[self.size-2, 0:self.column_choice] = 3\n",
    "            land[1:self.size-1, 0] = 3                                   \n",
    "            for col in land[1:self.size-1, self.column_choice+2:self.size-1].T:\n",
    "                traps = []\n",
    "                for i in range(int(np.round(1/4*len(col)))):        # make as many traps as 1/4 of the length of each column in the shore\n",
    "                    trap = np.random.choice(np.setdiff1d(range(len(col)), traps))\n",
    "                    col[trap] = 4\n",
    "                    traps.append(trap)\n",
    "            for col in land[2:self.size-2, 1:self.column_choice].T:\n",
    "                enemies = []\n",
    "                for i in range(int(np.round(1/4*len(col)))):        # populate enemies randomly inside the stronhold\n",
    "                    enemy = np.random.choice(np.setdiff1d(range(len(col)), enemies))\n",
    "                    col[enemy] = 5\n",
    "                    enemies.append(enemy)\n",
    "            intel_row = np.random.randint(1, len(land[2:self.size-2, 1:self.column_choice-1]))\n",
    "            intel_col = np.random.randint(1, len(land[2:self.size-2, 1:self.column_choice-1].T))\n",
    "            land[intel_row+2][self.column_choice-intel_col] = 6            # randomly insert intelligence into stronghold \n",
    "        else:                                                              # if stronghold is on right                          \n",
    "            land[1, self.column_choice:self.size] = 3\n",
    "            land[self.size-2, self.column_choice:self.size] = 3\n",
    "            land[1:self.size-1, self.size-1] = 3\n",
    "            for col in land[1:self.size-1, 1:self.column_choice-1].T:\n",
    "                traps = []\n",
    "                for i in range(int(np.round(1/4*len(col)))):        # make as many traps as 1/4 of the length of each column in the shore\n",
    "                    trap = np.random.choice(np.setdiff1d(range(len(col)), traps))\n",
    "                    col[trap] = 4\n",
    "                    traps.append(trap)\n",
    "            for col in land[2:self.size-2, self.column_choice+1:self.size-1].T:\n",
    "                enemies = []\n",
    "                for i in range(int(np.round(1/4*len(col)))):        # populate enemies randomly inside the stronhold\n",
    "                    enemy = np.random.choice(np.setdiff1d(range(len(col)), enemies))\n",
    "                    col[enemy] = 5\n",
    "                    enemies.append(enemy)\n",
    "            intel_row = np.random.randint(1, len(land[2:self.size-2, self.column_choice+1:self.size-1]))              \n",
    "            intel_col = np.random.randint(1, len(land[2:self.size-2, self.column_choice+1:self.size-1].T))\n",
    "            land[intel_row+2][self.column_choice+intel_col] = 6            # randomly insert intelligence into stronghold\n",
    "        entrances = []\n",
    "        for i in range(int(np.round(1/4*len(land[2:self.size-3, self.column_choice])))+1):        # make as many entrances as 1/4 of the length of the front wall\n",
    "            entrance = np.random.choice(np.setdiff1d(range(len(land[2:self.size-1, self.column_choice])), entrances))\n",
    "            land[2:self.size-2, self.column_choice][entrance] = 0\n",
    "            entrances.append(entrance)\n",
    "        return land\n",
    "        \n",
    "    def get_empty_cells_shore(self, n_cells):\n",
    "        if self.column_choice == self.size//2-1:\n",
    "            empty_cells_coord = np.where(self.land[1:self.size-1, self.column_choice+1:self.size-1] == 0)\n",
    "            selected_indices = np.random.choice(np.arange(len(empty_cells_coord[0])), n_cells)\n",
    "            selected_coordinates = empty_cells_coord[0][selected_indices]+1, empty_cells_coord[1][selected_indices]+len(self.land[1][:self.column_choice+1])\n",
    "        if self.column_choice == self.size//2+1:\n",
    "            empty_cells_coord = np.where(self.land[1:self.size-1, 1:self.column_choice] == 0)\n",
    "            selected_indices = np.random.choice(np.arange(len(empty_cells_coord[0])), n_cells)\n",
    "            selected_coordinates = empty_cells_coord[0][selected_indices]+1, empty_cells_coord[1][selected_indices]\n",
    "        if n_cells == 1:\n",
    "            return np.asarray(selected_coordinates).reshape(2,)\n",
    "        return selected_coordinates\n",
    "\n",
    "    def step(self, action):\n",
    "        # agent moves\n",
    "        # enemies move\n",
    "        self.time_elapsed += 1\n",
    "        return next_state, reward, done\n",
    "    \n",
    "    def reset(self):\n",
    "        self.time_elapsed = 0                                               # put time_elapsed to 0\n",
    "        self.position_agent = np.asarray(self.get_empty_cells_shore(1))       # position of the agent is a random cell on the shore numpy array\n",
    "        \n",
    "        # Calculate observations\n",
    "        #observations = self.calculate_observations()\n",
    "        #return observations\n",
    "\n",
    "    def render(self):                                                       # displays the land\n",
    "        envir_with_agent = self.land.copy()\n",
    "        envir_with_agent[self.position_agent[0], self.position_agent[1]] = 2\n",
    "        full_repr = \"\"\n",
    "        for r in range(self.size):\n",
    "            line = \"\"\n",
    "            for c in range(self.size):\n",
    "                string_repr = self.dict_map_display[envir_with_agent[r,c]]    \n",
    "                line += \"{0:2}\".format(string_repr)\n",
    "            full_repr += line + \"\\n\"\n",
    "        print(full_repr)\n",
    "\n",
    "    ''' Don't need this for Q-learning\n",
    "        def fill_transition_probability(self): # p.106\n",
    "            \n",
    "            return P\n",
    "        \n",
    "        def fill_reward_matrix(self):\n",
    "            \n",
    "            return R\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X X X X X X X X X X X X X X X X X X X X X \nX _ _ _ T _ T _ _ _ _ W W W W W W W W W W \nX _ _ _ _ T _ _ _ _ _ W _ _ _ _ _ _ _ _ W \nX T _ _ _ _ T _ _ _ _ W E E _ _ _ E _ _ W \nX _ _ _ T T _ _ _ _ _ W _ E E _ _ _ _ _ W \nX _ T _ _ _ T T _ _ _ W _ _ E _ _ E E _ W \nX _ _ T _ _ _ _ _ T _ _ _ I _ _ _ _ E _ W \nX T _ T _ A _ _ T _ _ W _ _ _ E E _ _ E W \nX _ _ _ T _ _ _ _ T _ _ E _ _ _ E _ _ _ W \nX _ _ T _ _ _ T T T _ _ _ _ _ _ _ _ _ E W \nX _ _ _ _ T _ T _ T _ W _ _ _ E _ E _ _ W \nX T _ _ _ _ _ _ T _ _ _ _ _ _ _ _ _ _ _ W \nX T T T _ _ T _ _ _ _ W _ E E _ _ _ _ E W \nX _ _ _ _ _ _ T T _ _ W E _ _ E E _ _ _ W \nX T T _ T _ _ _ _ _ _ W _ _ _ _ _ _ E _ W \nX _ _ T _ _ _ _ _ _ _ _ E _ _ _ _ E _ _ W \nX _ _ _ _ _ _ _ _ _ _ W _ _ E _ _ _ E _ W \nX _ T _ _ _ _ T _ T _ W _ E _ _ E _ _ E W \nX _ _ _ T _ T _ _ _ _ W _ _ _ E _ _ _ _ W \nX _ T _ _ T _ _ T _ _ W W W W W W W W W W \nX X X X X X X X X X X X X X X X X X X X X \n\n"
     ]
    }
   ],
   "source": [
    "stronghold = Stronghold(21)\n",
    "stronghold.reset()\n",
    "stronghold.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policies():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def random_policy(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # if row_choice == size//2:\n",
    "    #     choice_side = np.random.choice(('up', 'down'))\n",
    "    #     print(choice_side)\n",
    "    #     if choice_side == 'up':\n",
    "    #         row_choice = size//2-1\n",
    "    #     if choice_side == 'down':\n",
    "    #         row_choice = size//2+1\n",
    "\n",
    "    # if column_choice == size//2:\n",
    "    #     choice_side = np.random.choice((size//2-1, size//2+1)) # random choice between left and right\n",
    "    #     print(choice_side)\n",
    "    #     column_choice = choice_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choice = np.random.choice(('row', 'column')) # randomly deciding whether the stronghold will start 1 cell away from the middle row or middle column.\n",
    "# if choice == 'row':\n",
    "#     row_choice = np.random.choice((size//2-1, size//2+1))       # random choice between up or down cell\n",
    "#     land[row_choice, 1:size-1] = 3\n",
    "#     if row_choice == size//2-1:\n",
    "#         land[0:row_choice, 1] = 3\n",
    "#         land[0:row_choice, size-2] = 3\n",
    "#         land[0, 1:size-1] = 3\n",
    "#         land[1:row_choice]\n",
    "#         for row in land[row_choice+2:size-1, 1:size-1]:\n",
    "#             traps = []\n",
    "#             for i in range(int(np.round(1/4*len(row)))):        # make as many traps as 1/4 of the length of each row in the shore\n",
    "#                 trap = np.random.choice(np.setdiff1d(range(len(row)), traps))\n",
    "#                 row[trap] = 4\n",
    "#                 traps.append(trap)\n",
    "#     if row_choice == size//2+1:\n",
    "#         land[row_choice:size, 1] = 3\n",
    "#         land[row_choice:size, size-2] = 3\n",
    "#         land[size-1, 1:size-1] = 3\n",
    "#         for row in land[1:row_choice-1, 1:size-1]:\n",
    "#             traps = []\n",
    "#             for i in range(int(np.round(1/2*len(row)))):        # make as many traps as 1/4 of the length of each row in the shore\n",
    "#                 trap = np.random.choice(np.setdiff1d(range(len(row)), traps))\n",
    "#                 row[trap] = 4\n",
    "#                 traps.append(trap)\n",
    "#     entrances = []\n",
    "#     for i in range(int(np.round(1/4*len(land[row_choice,2:size-2])))+1):        # make as many entrances as 1/4 of the length of the front wall\n",
    "#         entrance = np.random.choice(np.setdiff1d(range(len(land[row_choice,2:size-1])), entrances))\n",
    "#         land[row_choice,2:size-1][entrance] = 0\n",
    "#         entrances.append(entrance)"
   ]
  }
 ]
}